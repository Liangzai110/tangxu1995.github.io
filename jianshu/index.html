<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Python爬虫--Scrapy爬取简书全站文章 | 2048</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Python爬虫--Scrapy爬取简书全站文章</h1><a id="logo" href="/.">2048</a><p class="description">Life is short, I use Python</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Python爬虫--Scrapy爬取简书全站文章</h1><div class="post-meta">May 18, 2018</div><a class="disqus-comment-count" href="/jianshu/#vcomment"><span class="valine-comment-count" data-xid="/jianshu/"></span><span> 条评论</span></a><div class="post-content"><hr>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jianshu/jianshu-logo.png" alt=""></p>
<hr>
<p>最近学习了 scrapy ，之前刚开始爬虫的时候有接触过这个框架，当时看了下工作原理有点难懂，现在慢慢地接触爬虫多了，回过头来开始了解爬虫框架，现在再来看它的工作流程就明白了很多。</p>
<p>本篇文章使用 scrapy 来爬取<a href="https://www.jianshu.com/" target="_blank" rel="noopener">简书</a>全站文章。</p>
<p>scrapy 工程创建与配置步骤(个人习惯)：</p>
<ol>
<li>创建 scrapy 工程，创建启动文件 start.py ，修改 settings.py 配置文件</li>
<li>进入 spider.py 文件开始写爬虫规则</li>
<li>item.py 中设置存储模板</li>
<li>写 pipeline 存入数据库</li>
</ol>
<hr>
<h1 id="创建-scrapy-工程"><a href="#创建-scrapy-工程" class="headerlink" title="创建 scrapy 工程"></a>创建 scrapy 工程</h1><p>windows 系统在 scrapy 工程文件根目录：打开命令行工具，输入命令创建工程。<br><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy startproject <span class="string">[工程名字]</span></span><br></pre></td></tr></table></figure></p>
<p>cd 到工程文件夹下，创建爬虫文件，默认使用 basic 模板，同样在命令行中。输入<br><figure class="highlight accesslog"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy genspider <span class="string">[爬虫名字]</span> <span class="string">[爬虫网址]</span></span><br></pre></td></tr></table></figure></p>
<p>这样就完成了一个 scrapy 工程的创建。但是这里爬取简书全站我使用的是  crawlspider 爬虫，其有可编写的爬虫规则，使用起来比较方便。</p>
<p>为了方便启动工程，我都会在创建好 scrapy 后再来创建一个启动文件 start.py 。</p>
<p>修改 settings.py 文件，将其中的遵守 robots.txt 协议关闭，开启 headers 其它配置等需要的时候再去更改。</p>
<hr>
<h1 id="进入-spider-py-写爬虫规则"><a href="#进入-spider-py-写爬虫规则" class="headerlink" title="进入 spider.py 写爬虫规则"></a>进入 spider.py 写爬虫规则</h1><p>这次爬取的是简书全站的文章，因此要找所有文章的链接规则，每篇文章阅读到最底部，简书会推荐给我们一些其它文章，几乎每篇文章下面都会有推荐，因此我们从这里入手，查看了源代码，发现了它们的链接形式都大致相同，<a href="https://www.jianshu.com/p/7a4879ef6f8d" target="_blank" rel="noopener">https://www.jianshu.com/p/7a4879ef6f8d</a> ，<a href="https://www.jianshu.com/p/cde1742518c8" target="_blank" rel="noopener">https://www.jianshu.com/p/cde1742518c8</a> ，如图。    </p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jianshu/jianshu3.jpg" alt=""></p>
<p>可以看到，都是 p 后面接上一大串数字字母的混合字符串，因此可以写出它的规则，使用正则表达式，如下。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">rules = (</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'.+/p/[a-z0-9].+'</span>), callback=<span class="string">'parse_detail'</span>, follow=<span class="keyword">True</span>),</span><br><span class="line">    )</span><br></pre></td></tr></table></figure></p>
<p>rules 是一个元组，其中，Rule 写的是爬虫的规则；callback 指的是回调函数，也就是当获取到了前面取到的 url 之后，程序该去调用哪一个函数的操作，而这里就是去调用 parse_detail 这个函数； follow 表示跟进，如果其 ==True 表示要继续跟进，也就是我们进入一片文章之后，要继续跟进下一篇文章。</p>
<p>在进入一篇文章之后，我们要获取到它的标题，发布者，发布时间，还有内容这四个部分。这里使用 xpath 方法来获取。</p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jianshu/jianshu1.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_detail</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    title = response.xpath(<span class="string">"/html/body/div[1]/div[1]/div[1]/h1/text()"</span>).get()</span><br><span class="line">    pub_name = response.xpath(<span class="string">"/html/body/div[1]/div[1]/div[1]/div[1]/div/span/a/text()"</span>).get()</span><br><span class="line">    release_time = response.xpath(<span class="string">"/html/body/div[1]/div[1]/div[1]/div[1]/div/div/span[1]/text()"</span>).get()</span><br><span class="line">    content = response.xpath(<span class="string">"/html/body/div[1]/div[1]/div[1]/div[2]/div"</span>).get()</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="items-py-中设置存储模板"><a href="#items-py-中设置存储模板" class="headerlink" title="items.py 中设置存储模板"></a>items.py 中设置存储模板</h1><p>在上面已经决定了要采集者四个信息，那么在 item.py 中设置好这四项。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JianshuItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    pub_name = scrapy.Field()</span><br><span class="line">    release_time = scrapy.Field()</span><br><span class="line">    content = scrapy.Field()</span><br></pre></td></tr></table></figure></p>
<p>最后在 parse_detail 尾部加入以下代码，再将 item 返回去。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">item = JianshuItem(title=title, pub_name=pub_name, release_time=release_time, content=content)</span><br><span class="line"><span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure></p>
<hr>
<h1 id="pipelines-py"><a href="#pipelines-py" class="headerlink" title="pipelines.py"></a>pipelines.py</h1><p>到这里就可以运行一下程序了，看一下是否能正常输出我们采集的信息。</p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jianshu/jianshu2.jpg" alt=""></p>
<p>可以看到这里可以正常爬取数据，接下来需要将其存入数据库。存入数据库需要在 pipelines.py 中编写相应的代码。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JianshuMongoDBPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.DB_URI = <span class="string">'localhost'</span></span><br><span class="line">        self.DB_PORT = <span class="number">27017</span></span><br><span class="line">        self.client = pymongo.MongoClient(self.DB_URI, self.DB_PORT)</span><br><span class="line">        self.db = self.client[<span class="string">'jianshu'</span>]</span><br><span class="line">        self.collection = self.db[<span class="string">'jianshu_spider'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spdier)</span>:</span></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="keyword">if</span> self.collection.insert(dict(item)):</span><br><span class="line">                print(<span class="string">'保存至MongoDB成功'</span>)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">'保存至MongoDB失败！'</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> error:</span><br><span class="line">            print(error)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></p>
<p>在 pipelines.py 中写好 MongoDB 部分后，在 settings.py 中将对应的 pipelines 打开。</p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jianshu/jianshusettings.jpg" alt=""></p>
<p>然后重新运行 start.py ，启动爬虫。</p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jianshu/jianshumongo.jpg" alt=""></p>
<p>启动爬虫后，一直没有遇到反爬措施，运行了大概30分钟， ROBO 3T 管理工具得到的数据有3300条。<del>感觉速度还是慢，有待优化</del>(突然发现在 settings.py 中设置了1s延时….关掉之后快多了。。 )</p>
<hr>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Tang</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/jianshu/">http://yoursite.com/jianshu/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><div class="tags"></div><div class="post-nav"><a class="pre" href="/bubble_sort/">冒泡排序</a><a class="next" href="/scrapy/">Scrapy</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'3GQ0exdcRfacks3SpIDCHJxG-gzGzoHsz',
  appKey:'orhKsu5i4zUuOonEqTIBEPcF',
  placeholder:'ヾﾉ≧∀≦)o来啊，快活啊!',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Pycharm/">Pycharm</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Pycharm/日常/">日常</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/日常/">日常</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">2</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/网页框架/" style="font-size: 15px;">网页框架</a> <a href="/tags/动态-爬虫/" style="font-size: 15px;">动态 爬虫</a> <a href="/tags/PHP/" style="font-size: 15px;">PHP</a> <a href="/tags/爬虫-selenium/" style="font-size: 15px;">爬虫 selenium</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Scrapy/" style="font-size: 15px;">Scrapy</a> <a href="/tags/Pycharm/" style="font-size: 15px;">Pycharm</a> <a href="/tags/动态网页/" style="font-size: 15px;">动态网页</a> <a href="/tags/静态网页/" style="font-size: 15px;">静态网页</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/scrapy_login/">Scrapy模拟登录</a></li><li class="post-list-item"><a class="post-list-link" href="/bookSpdier2/">多进程爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/bookSpdier/">多线程爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/qiniu/">七牛云数据迁移至网易nos</a></li><li class="post-list-item"><a class="post-list-link" href="/Pycharm/">Pycharm</a></li><li class="post-list-item"><a class="post-list-link" href="/maoyan_encrypt/">Python爬虫--猫眼加密字符</a></li><li class="post-list-item"><a class="post-list-link" href="/laravel_admin/">PHP框架--Laravel</a></li><li class="post-list-item"><a class="post-list-link" href="/django/">Django</a></li><li class="post-list-item"><a class="post-list-link" href="/quick_sort/">Python算法--快速排序</a></li><li class="post-list-item"><a class="post-list-link" href="/insert_sort/">Python算法--插入排序</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">2048.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" color="0,0,0" opacity="0.5" zindex="-2" count="50" src="//lib.baomitu.com/canvas-nest.js/2.0.3/canvas-nest.umd.js"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>