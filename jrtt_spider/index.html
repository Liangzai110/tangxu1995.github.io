<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>爬虫之今日头条街拍 | 2048</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">爬虫之今日头条街拍</h1><a id="logo" href="/.">2048</a><p class="description">Life is short, I use Python</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">爬虫之今日头条街拍</h1><div class="post-meta">Apr 11, 2018<span> | </span><span class="category"><a href="/categories/爬虫/">爬虫</a></span></div><a class="disqus-comment-count" href="/jrtt_spider/#vcomment"><span class="valine-comment-count" data-xid="/jrtt_spider/"></span><span> 条评论</span></a><div class="post-content"><hr>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jrtt/jrtt-logo.png" alt=""></p>
<hr>
<p>前面的爬虫都是静态页面，遇到动态页面该如何爬取，当时困惑了好久，不知道如何下手，参考了几篇其他大佬的文章，才慢慢有一点懂。</p>
<p>这次的网页是动态加载的今日头条街拍图集网页。看了崔大大的教程，自己动手码一下代码，熟悉一下动态页面的爬虫步骤。</p>
<p>动态页面肯定不能像静态页面一样直接取数据，因为它的数据都是通过 js 渲染进来的，因此先找到对应的数据 js 文件。</p>
<p>首先，先来规划下步骤：</p>
<p>1.观察 js 请求，查看数据通过哪个文件传输。</p>
<p>2.对 js 文件进行请求，获得信息。</p>
<p>3.提取数据，对数据进行处理。</p>
<hr>
<h1 id="查看-js-请求"><a href="#查看-js-请求" class="headerlink" title="查看 js 请求"></a>查看 js 请求</h1><p>打开今日头条，搜索框内输入关键词“街拍”，跳转到街拍页面，往下拉，能看到图片一直在加载新的，而网址没有改变，动态的没错了，打开 F12 ，网页继续往下拉，Network 下出现了新的请求，并且这些请求构造都差不多，随便点击一个请求，打开 Preview ，里面是 json 格式的，其中有图片标题，也有图片的 url 信息，看到里面就是想要采集的数据，要找的就是它。</p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jrtt/jrtt1.jpg" alt=""></p>
<p>请求方式为 GET , 再来看下 Form Data ，有 offset , format , keyword , autoload , count , cur_tab , from 这几个参数，offset 是偏移量，也就是一共刷新出来的图片数量，keyword 是关键词， count 是每一页刷新出来的图片数量， 其它参数没什么重要意义，构造网址时直接加上去就行了。</p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jrtt/jrtt2.jpg" alt=""></p>
<h1 id="对js进行请求"><a href="#对js进行请求" class="headerlink" title="对js进行请求"></a>对js进行请求</h1><p>想要对 js 进行请求，需要先对网址进行构造。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line">headers = &#123;</span><br><span class="line">  <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.62 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Form Data 中的参数</span></span><br><span class="line">params = &#123;</span><br><span class="line">        <span class="string">'offset'</span>: page,</span><br><span class="line">        <span class="string">'format'</span>: <span class="string">'json'</span>,</span><br><span class="line">        <span class="string">'keyword'</span>: <span class="string">'街拍'</span>,</span><br><span class="line">        <span class="string">'autoload'</span>: <span class="string">'true'</span>,</span><br><span class="line">        <span class="string">'count'</span>: <span class="string">'20'</span>,</span><br><span class="line">        <span class="string">'cur_tab'</span>: <span class="string">'3'</span>,</span><br><span class="line">        <span class="string">'from'</span>: <span class="string">'gallery'</span></span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment"># 对网址进行构造， 使用urlencode方法</span></span><br><span class="line">url = <span class="string">'https://www.toutiao.com/search_content/?'</span> + urlencode(params)</span><br></pre></td></tr></table></figure>
<p>构造完毕，对网址进行请求。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对网址进行请求，获取到的json格式</span></span><br><span class="line">response = requests.get(url, headers=headers)</span><br><span class="line"><span class="keyword">if</span> response.status_code == <span class="number">200</span>:  </span><br><span class="line">    <span class="keyword">return</span> response.json()</span><br></pre></td></tr></table></figure></p>
<h1 id="提取信息"><a href="#提取信息" class="headerlink" title="提取信息"></a>提取信息</h1><p>经过上一步对 js 进行请求后，得到和之前看到的 Preview 里面一样的信息，开始对数据进行提取处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">json = response.json()</span><br><span class="line"><span class="comment"># 判断json的data，如果存在继续下一步，其实这里用.get方法更好，因为.get方法如果获取一个不存在的属性时不会报错，而直接使用['']这种方法，如果不存在此属性，就会直接报错，影响程序效率</span></span><br><span class="line"><span class="keyword">if</span> json[<span class="string">'data'</span>]:</span><br><span class="line">  <span class="comment"># data是个列表，对列表中数据继续遍历</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> json[<span class="string">'data'</span>]:</span><br><span class="line">      <span class="comment"># 获取到title信息和图片地址信息</span></span><br><span class="line">        title = item.get(<span class="string">'title'</span>)</span><br><span class="line">        image_urls = item.get(<span class="string">'image_list'</span>)</span><br><span class="line">        <span class="comment"># 因为有多张图片，因此图片信息被装在一个列表中，需要继续遍历</span></span><br><span class="line">        <span class="keyword">for</span> image_url <span class="keyword">in</span> image_urls:</span><br><span class="line">          <span class="comment"># 这里把图片url中的list换成large，提取大图</span></span><br><span class="line">            image = <span class="string">'http://'</span> + image_url.get(<span class="string">'url'</span>).strip(<span class="string">'//'</span>).replace(<span class="string">'list'</span>, <span class="string">'large'</span>)</span><br><span class="line">            <span class="comment"># 返回image和title信息</span></span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'image'</span>: image,</span><br><span class="line">                <span class="string">'title'</span>: title</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>
<hr>
<h1 id="保存数据"><a href="#保存数据" class="headerlink" title="保存数据"></a>保存数据</h1><h2 id="保存到本地文件夹"><a href="#保存到本地文件夹" class="headerlink" title="保存到本地文件夹"></a>保存到本地文件夹</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"><span class="comment"># 判断当前文件路径下是否存在以图片的标题命名的文件夹，如果不存在，就新建文件夹</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(item.get(<span class="string">'title'</span>)):</span><br><span class="line">    os.mkdir(item.get(<span class="string">'title'</span>))</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">  <span class="comment"># 请求图片的url地址</span></span><br><span class="line">    response = requests.get(item.get(<span class="string">'image'</span>))</span><br><span class="line">    <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">        file_path = <span class="string">'&#123;0&#125;/&#123;1&#125;.&#123;2&#125;'</span>.format(item.get(<span class="string">'title'</span>), md5(response.content).hexdigest(), <span class="string">'jpg'</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_path):</span><br><span class="line">            <span class="keyword">with</span> open(file_path, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                f.write(response.content)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            print(<span class="string">'已经下载过！'</span>)</span><br><span class="line"><span class="keyword">except</span> requests.ConnectionError:</span><br><span class="line">    print(<span class="string">'连接失败!'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jrtt/jrtt3.jpg" alt=""></p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jrtt/jrtt4.jpg" alt=""></p>
<h2 id="保存到-MongoDB-数据库。"><a href="#保存到-MongoDB-数据库。" class="headerlink" title="保存到 MongoDB 数据库。"></a>保存到 MongoDB 数据库。</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_mongo</span><span class="params">(data)</span>:</span></span><br><span class="line">    client = pymongo.MongoClient(<span class="string">'localhost'</span>, <span class="number">27017</span>)</span><br><span class="line">    db = client[<span class="string">'jrtt'</span>]</span><br><span class="line">    collection = db[<span class="string">'jrtt_spider'</span>]</span><br><span class="line">    <span class="keyword">if</span> collection.insert(data):</span><br><span class="line">        print(<span class="string">'保存到MongoDB成功'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/jrtt/jrttmongo.jpg" alt=""></p>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> hashlib <span class="keyword">import</span> md5</span><br><span class="line"><span class="keyword">from</span> urllib.parse <span class="keyword">import</span> urlencode</span><br><span class="line"><span class="keyword">from</span> multiprocessing <span class="keyword">import</span> Pool</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line">    <span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/67.0.3396.62 Safari/537.36'</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_page_source</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.json()</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        print(<span class="string">'error'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_content</span><span class="params">(json)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> json[<span class="string">'data'</span>]:</span><br><span class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> json[<span class="string">'data'</span>]:</span><br><span class="line">            title = item.get(<span class="string">'title'</span>)</span><br><span class="line">            image_urls = item.get(<span class="string">'image_list'</span>)</span><br><span class="line">            <span class="keyword">for</span> image_url <span class="keyword">in</span> image_urls:</span><br><span class="line">                image = <span class="string">'http://'</span> + image_url.get(<span class="string">'url'</span>).strip(<span class="string">'//'</span>).replace(<span class="string">'list'</span>, <span class="string">'large'</span>)</span><br><span class="line">                <span class="keyword">yield</span> &#123;</span><br><span class="line">                    <span class="string">'image'</span>: image,</span><br><span class="line">                    <span class="string">'title'</span>: title</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_file</span><span class="params">(item)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(item.get(<span class="string">'title'</span>)):</span><br><span class="line">        os.mkdir(item.get(<span class="string">'title'</span>))</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(item.get(<span class="string">'image'</span>))</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            file_path = <span class="string">'&#123;0&#125;/&#123;1&#125;.&#123;2&#125;'</span>.format(item.get(<span class="string">'title'</span>), md5(response.content).hexdigest(), <span class="string">'jpg'</span>)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_path):</span><br><span class="line">                <span class="keyword">with</span> open(file_path, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                    f.write(response.content)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">'已经下载过！'</span>)</span><br><span class="line">    <span class="keyword">except</span> requests.ConnectionError:</span><br><span class="line">        print(<span class="string">'连接失败!'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_mongo</span><span class="params">(data)</span>:</span></span><br><span class="line">    client = pymongo.MongoClient(<span class="string">'localhost'</span>, <span class="number">27017</span>)</span><br><span class="line">    db = client[<span class="string">'jrtt'</span>]</span><br><span class="line">    collection = db[<span class="string">'jrtt_spider'</span>]</span><br><span class="line">    <span class="keyword">if</span> collection.insert(data):</span><br><span class="line">        print(<span class="string">'保存到MongoDB成功'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(page)</span>:</span></span><br><span class="line">    params = &#123;</span><br><span class="line">        <span class="string">'offset'</span>: page,</span><br><span class="line">        <span class="string">'format'</span>: <span class="string">'json'</span>,</span><br><span class="line">        <span class="string">'keyword'</span>: <span class="string">'街拍'</span>,</span><br><span class="line">        <span class="string">'autoload'</span>: <span class="string">'true'</span>,</span><br><span class="line">        <span class="string">'count'</span>: <span class="string">'20'</span>,</span><br><span class="line">        <span class="string">'cur_tab'</span>: <span class="string">'3'</span>,</span><br><span class="line">        <span class="string">'from'</span>: <span class="string">'gallery'</span></span><br><span class="line">    &#125;</span><br><span class="line">    url = <span class="string">'https://www.toutiao.com/search_content/?'</span> + urlencode(params)</span><br><span class="line">    json = get_page_source(url)</span><br><span class="line">    items = get_content(json)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</span><br><span class="line">      <span class="comment"># 保存至本地文件夹</span></span><br><span class="line">        save_to_file(item)</span><br><span class="line">      <span class="comment"># 保存标题和链接到MongoDB数据库</span></span><br><span class="line">        save_to_mongo(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    START = <span class="number">1</span></span><br><span class="line">    END = <span class="number">20</span></span><br><span class="line">    pool = Pool()</span><br><span class="line">    groups = ([x ` <span class="number">20</span> <span class="keyword">for</span> x <span class="keyword">in</span> range(START, END+<span class="number">1</span>)])</span><br><span class="line">    pool.map(main, groups)</span><br><span class="line">    pool.close()</span><br><span class="line">    pool.join()</span><br></pre></td></tr></table></figure>
<hr>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Tang</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/jrtt_spider/">http://yoursite.com/jrtt_spider/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><div class="tags"><a href="/tags/爬虫/">爬虫</a><a href="/tags/动态网页/">动态网页</a></div><div class="post-nav"><a class="pre" href="/jd_comments/">Python爬虫--京东商品评论</a><a class="next" href="/maoyan_spider/">爬虫之猫眼排行榜TOP100</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'3GQ0exdcRfacks3SpIDCHJxG-gzGzoHsz',
  appKey:'orhKsu5i4zUuOonEqTIBEPcF',
  placeholder:'ヾﾉ≧∀≦)o来啊，快活啊!',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Pycharm/">Pycharm</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Pycharm/日常/">日常</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/日常/">日常</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">2</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/网页框架/" style="font-size: 15px;">网页框架</a> <a href="/tags/动态-爬虫/" style="font-size: 15px;">动态 爬虫</a> <a href="/tags/PHP/" style="font-size: 15px;">PHP</a> <a href="/tags/爬虫-selenium/" style="font-size: 15px;">爬虫 selenium</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Scrapy/" style="font-size: 15px;">Scrapy</a> <a href="/tags/Pycharm/" style="font-size: 15px;">Pycharm</a> <a href="/tags/动态网页/" style="font-size: 15px;">动态网页</a> <a href="/tags/静态网页/" style="font-size: 15px;">静态网页</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/scrapy_login/">Scrapy模拟登录</a></li><li class="post-list-item"><a class="post-list-link" href="/bookSpdier2/">多进程爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/bookSpdier/">多线程爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/qiniu/">七牛云数据迁移至网易nos</a></li><li class="post-list-item"><a class="post-list-link" href="/Pycharm/">Pycharm</a></li><li class="post-list-item"><a class="post-list-link" href="/maoyan_encrypt/">Python爬虫--猫眼加密字符</a></li><li class="post-list-item"><a class="post-list-link" href="/laravel_admin/">PHP框架--Laravel</a></li><li class="post-list-item"><a class="post-list-link" href="/django/">Django</a></li><li class="post-list-item"><a class="post-list-link" href="/quick_sort/">Python算法--快速排序</a></li><li class="post-list-item"><a class="post-list-link" href="/insert_sort/">Python算法--插入排序</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">2048.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" color="0,0,0" opacity="0.5" zindex="-2" count="50" src="//lib.baomitu.com/canvas-nest.js/2.0.3/canvas-nest.umd.js"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>