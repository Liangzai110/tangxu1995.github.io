<!DOCTYPE html><html lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>爬虫之猫眼排行榜TOP100 | 2048</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/normalize/8.0.1/normalize.min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//lib.baomitu.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//lib.baomitu.com/jquery/3.3.1/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">爬虫之猫眼排行榜TOP100</h1><a id="logo" href="/.">2048</a><p class="description">Life is short, I use Python</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">爬虫之猫眼排行榜TOP100</h1><div class="post-meta">Mar 29, 2018<span> | </span><span class="category"><a href="/categories/爬虫/">爬虫</a></span></div><a class="disqus-comment-count" href="/maoyan_spider/#vcomment"><span class="valine-comment-count" data-xid="/maoyan_spider/"></span><span> 条评论</span></a><div class="post-content"><hr>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/maoyan/maoyan-logo.png" alt=""></p>
<hr>
<p>网页分成静态网页和动态网页：  </p>
<p>静态网页是相对于动态网页而言，是指没有后台数据库、不含程序和不可交互的网页。静态网页相对更新起来比较麻烦，适用于一般更新较少的展示型网站。一般是网站呈现出来后网站的内容及结构就不会再发生改变了。  </p>
<p>而动态网页则不然，页面代码虽然没有变，但是显示的内容却是可以随着时间、环境或者数据库操作的结果而发生改变的能链接数据库，将数据库中的内容展现在页面中，同时允许用户与网站进行交互。我第一个接触的爬虫小项目就是猫眼爬虫。</p>
<p>因为猫眼网站是静态网站，因此我们只要先拿到原网址，获取内容后进行解析，再去分析多页信息等操作就可以了，作为入门项目非常简单。  </p>
<p>写每个工程都要有明确思路，对于这个项目，步骤有：</p>
<p>1.获取到网页源代码。</p>
<p>2.使用 bs4 , xpath 等工具解析内容，提取想获取的内容。</p>
<p>3.分析网页如何进行翻页操作，构造翻页的网址，继续提取内容。</p>
<p>4.提取出的信息该如何处理(保存至文件或者数据库)</p>
<p>排行榜网址 <a href="http://maoyan.com/board/4" target="_blank" rel="noopener">http://maoyan.com/board/4</a></p>
<p>网站首页如下图所示：  </p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/maoyan/maoyan1.jpg" alt=""></p>
<hr>
<h1 id="获取网页源代码"><a href="#获取网页源代码" class="headerlink" title="获取网页源代码"></a>获取网页源代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">headers = &#123;</span><br><span class="line">	<span class="string">'User-Agent'</span>: <span class="string">'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 SE 2.X MetaSr 1.0'</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment"># 直接对网址进行请求</span></span><br><span class="line">url = <span class="string">'http://maoyan.com/board/4'</span>    </span><br><span class="line">response = requests.get(url, headers=headers)</span><br></pre></td></tr></table></figure>
<h1 id="提取信息"><a href="#提取信息" class="headerlink" title="提取信息"></a>提取信息</h1><p>要提取各个电影的排名，影片名称，演员，上映时间，评分信息，打开 F12 开发工具，发现电影信息都被放在一个个 dd 标签内，因此使用 bs 的 select 方法，选中 dd 标签，select 输出是列表，可以迭代，所以继续用 for 循环遍历列表，再根据具体信息进行具体筛选，使用 .text 输出文本。</p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/maoyan/maoyan2.jpg" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">soup = Beautifulsoup(response.text, <span class="string">'lxml'</span>)</span><br><span class="line"><span class="keyword">for</span> items <span class="keyword">in</span> soup.select(<span class="string">'dd'</span>):</span><br><span class="line">      rank = items.select(<span class="string">'.board-index'</span>)[<span class="number">0</span>].text</span><br><span class="line">      title = items.select(<span class="string">'a'</span>)[<span class="number">1</span>].text</span><br><span class="line">      actor_name = items.select(<span class="string">'.star'</span>)[<span class="number">0</span>].text.strip()</span><br><span class="line">      release_time = items.select(<span class="string">'.releasetime'</span>)[<span class="number">0</span>].text</span><br><span class="line">      integer = items.select(<span class="string">'.integer'</span>)[<span class="number">0</span>].text</span><br><span class="line">      fraction = items.select(<span class="string">'.fraction'</span>)[<span class="number">0</span>].text</span><br><span class="line">      goal = integer + fraction</span><br><span class="line">      <span class="keyword">yield</span> &#123;</span><br><span class="line">     	 <span class="string">'range'</span>: rank,</span><br><span class="line">     	 <span class="string">'title'</span>: title,</span><br><span class="line">     	 <span class="string">'actor_name'</span>: actor_name,</span><br><span class="line">     	 <span class="string">'release_time'</span>: release_time,</span><br><span class="line">     	 <span class="string">'goal'</span>: goal</span><br><span class="line">         	 &#125;</span><br></pre></td></tr></table></figure>
<h1 id="分析网页的翻页操作"><a href="#分析网页的翻页操作" class="headerlink" title="分析网页的翻页操作"></a>分析网页的翻页操作</h1><p>这里就直接点击下一页来查看网址的变化来找出页码规律，点击下一页发现网址后面出现了 offset 参数，每点击下一页，offset 后面的数值就+10，所以现在可以开始构造每一页的网址，来进行爬去整个 TOP100 排行榜，这里只爬取了前10页数据。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 翻页网址的构造</span></span><br><span class="line">final_url = <span class="string">'http://maoyan.com/board/4?offset=&#123;&#125;'</span>.format(page)</span><br></pre></td></tr></table></figure></p>
<p>上面是构造出的最终网址，通过传入 page 可以给网址赋予不同的操作，requests 再去请求就可以了。</p>
<h1 id="对提取数据的操作"><a href="#对提取数据的操作" class="headerlink" title="对提取数据的操作"></a>对提取数据的操作</h1><p>提取数据后，可以存进文件里或者数据库中。</p>
<h2 id="存进文件"><a href="#存进文件" class="headerlink" title="存进文件"></a>存进文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 以追加方式，编码方式为utf-8</span></span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'reslut.txt'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(item)</span><br></pre></td></tr></table></figure>
<p>这样项目下就会生成一个 result.txt 文件，信息以字典方式存放入文件中。</p>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/maoyan/maoyan3.jpg" alt=""></p>
<h2 id="将数据存入-mysql-数据库"><a href="#将数据存入-mysql-数据库" class="headerlink" title="将数据存入 mysql 数据库"></a>将数据存入 mysql 数据库</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">db = pymysql.connect(<span class="string">'localhost'</span>, <span class="string">'root'</span>, <span class="string">'root'</span>, <span class="string">'maoyan'</span>)</span><br><span class="line">cursor = db.cursor()</span><br><span class="line">sql = <span class="string">'''insert into maoyan_spider(rank, title, actor_name, release_time, goal) values(%s,%s,%s,%s,%s)'''</span></span><br><span class="line">cursor.execute(sql, (data[<span class="string">'rank'</span>], data[<span class="string">'title'</span>], data[<span class="string">'actor_name'</span>], data[<span class="string">'release_time'</span>], data[<span class="string">'goal'</span>]))</span><br><span class="line">db.commit()</span><br><span class="line">db.close()</span><br><span class="line">print(<span class="string">'存入mysql成功'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/maoyan/maoyanmysql.jpg" alt=""></p>
<h2 id="将数据存入-mongoDB-数据库"><a href="#将数据存入-mongoDB-数据库" class="headerlink" title="将数据存入 mongoDB 数据库"></a>将数据存入 mongoDB 数据库</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">client = pymongo.MongoClient(<span class="string">'localhost'</span>, <span class="number">27017</span>)</span><br><span class="line">db = client[<span class="string">'maoyan'</span>]</span><br><span class="line">collection = db[<span class="string">'maoyan_spdier'</span>]</span><br><span class="line">collection.insert(data)</span><br><span class="line">print(<span class="string">'保存到mongodb成功'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="https://hexo-pics.nos-eastchina1.126.net/maoyan/maoyanmongo.jpg" alt=""></p>
<h1 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"><span class="keyword">import</span> pymongo</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_page_source</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url, headers=headers)</span><br><span class="line">        <span class="keyword">if</span> response.status_code == <span class="number">200</span>:</span><br><span class="line">            <span class="keyword">return</span> response.text</span><br><span class="line">    <span class="keyword">except</span> Exception:</span><br><span class="line">        print(<span class="string">'error'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_content</span><span class="params">(html)</span>:</span></span><br><span class="line">    soup = BeautifulSoup(html, <span class="string">'lxml'</span>)</span><br><span class="line">    <span class="keyword">for</span> items <span class="keyword">in</span> soup.select(<span class="string">'dd'</span>):</span><br><span class="line">        rank = items.select(<span class="string">'.board-index'</span>)[<span class="number">0</span>].text</span><br><span class="line">        title = items.select(<span class="string">'a'</span>)[<span class="number">1</span>].text</span><br><span class="line">        name = items.select(<span class="string">'.star'</span>)[<span class="number">0</span>].text.strip()</span><br><span class="line">        time = items.select(<span class="string">'.releasetime'</span>)[<span class="number">0</span>].text</span><br><span class="line">        integer = items.select(<span class="string">'.integer'</span>)[<span class="number">0</span>].text</span><br><span class="line">        fraction = items.select(<span class="string">'.fraction'</span>)[<span class="number">0</span>].text</span><br><span class="line">        goal = integer + fraction</span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'range'</span>: rank,</span><br><span class="line">            <span class="string">'title'</span>: title,</span><br><span class="line">            <span class="string">'name'</span>: name,</span><br><span class="line">            <span class="string">'time'</span>: time,</span><br><span class="line">            <span class="string">'goal'</span>: goal</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">write_to_file</span><span class="params">(data)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(<span class="string">'result.txt'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(str(data) + <span class="string">'\n'</span>)</span><br><span class="line">        print(<span class="string">'保存到文本文件成功'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_mysql</span><span class="params">(data)</span>:</span></span><br><span class="line">    db = pymysql.connect(<span class="string">'localhost'</span>, <span class="string">'root'</span>, <span class="string">'root'</span>, <span class="string">'maoyan'</span>)</span><br><span class="line">    cursor = db.cursor()</span><br><span class="line">    sql = <span class="string">'''insert into maoyan_spider(rank, title, actor_name, release_time, goal) values(%s,%s,%s,%s,%s)'''</span></span><br><span class="line">    cursor.execute(sql, (data[<span class="string">'rank'</span>], data[<span class="string">'title'</span>], data[<span class="string">'actor_name'</span>], data[<span class="string">'release_time'</span>], data[<span class="string">'goal'</span>]))</span><br><span class="line">    <span class="comment"># cursor.execute('''''', (data['rank'], data['title'], data['mvname'], data['release_time'], data['goal']))</span></span><br><span class="line">    db.commit()</span><br><span class="line">    db.close()</span><br><span class="line">    print(<span class="string">'存入mysql成功'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">save_to_mongo</span><span class="params">(data)</span>:</span></span><br><span class="line">    client = pymongo.MongoClient(<span class="string">'localhost'</span>, <span class="number">27017</span>)</span><br><span class="line">    db = client[<span class="string">'maoyan'</span>]</span><br><span class="line">    collection = db[<span class="string">'maoyan_spdier'</span>]</span><br><span class="line">    collection.insert(data)</span><br><span class="line">    print(<span class="string">'保存到mongodb成功'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    url = <span class="string">'http://maoyan.com/board/4?offset=0'</span></span><br><span class="line">    html = get_page_source(url)</span><br><span class="line">    data = get_content(html)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> data:</span><br><span class="line">      <span class="comment"># 存入文本文件</span></span><br><span class="line">        write_to_file(item)</span><br><span class="line">      <span class="comment"># 存入mysql数据库</span></span><br><span class="line">        save_to_mysql(item)</span><br><span class="line">      <span class="comment"># 存入mongoDB数据库</span></span><br><span class="line">        save_to_mongo(item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line"> <span class="keyword">for</span> page <span class="keyword">in</span> range(<span class="number">0</span>, <span class="number">10</span>):</span><br><span class="line">      main(page*<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<hr>
</div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong>Tang</li><li class="post-copyright-link"><strong>本文链接：</strong><a href="/maoyan_spider/">http://yoursite.com/maoyan_spider/</a></li><li class="post-copyright-license"><strong>版权声明：</strong>本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！</li></ul></div><br><div class="tags"><a href="/tags/爬虫/">爬虫</a><a href="/tags/静态网页/">静态网页</a></div><div class="post-nav"><a class="pre" href="/jrtt_spider/">爬虫之今日头条街拍</a></div><div id="vcomment"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="//unpkg.com/valine@latest/dist/Valine.min.js"></script><script>var notify = 'false' == true ? true : false;
var verify = 'false' == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;
window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'3GQ0exdcRfacks3SpIDCHJxG-gzGzoHsz',
  appKey:'orhKsu5i4zUuOonEqTIBEPcF',
  placeholder:'ヾﾉ≧∀≦)o来啊，快活啊!',
  avatar:'mm',
  guest_info:guest_info,
  pageSize:'10'
})</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Pycharm/">Pycharm</a><span class="category-list-count">1</span><ul class="category-list-child"><li class="category-list-item"><a class="category-list-link" href="/categories/Pycharm/日常/">日常</a><span class="category-list-count">1</span></li></ul></li><li class="category-list-item"><a class="category-list-link" href="/categories/日常/">日常</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/爬虫/">爬虫</a><span class="category-list-count">2</span></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/爬虫/" style="font-size: 15px;">爬虫</a> <a href="/tags/网页框架/" style="font-size: 15px;">网页框架</a> <a href="/tags/动态-爬虫/" style="font-size: 15px;">动态 爬虫</a> <a href="/tags/PHP/" style="font-size: 15px;">PHP</a> <a href="/tags/爬虫-selenium/" style="font-size: 15px;">爬虫 selenium</a> <a href="/tags/算法/" style="font-size: 15px;">算法</a> <a href="/tags/Python/" style="font-size: 15px;">Python</a> <a href="/tags/Scrapy/" style="font-size: 15px;">Scrapy</a> <a href="/tags/Pycharm/" style="font-size: 15px;">Pycharm</a> <a href="/tags/动态网页/" style="font-size: 15px;">动态网页</a> <a href="/tags/静态网页/" style="font-size: 15px;">静态网页</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/scrapy_login/">Scrapy模拟登录</a></li><li class="post-list-item"><a class="post-list-link" href="/bookSpdier2/">多进程爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/bookSpdier/">多线程爬虫</a></li><li class="post-list-item"><a class="post-list-link" href="/qiniu/">七牛云数据迁移至网易nos</a></li><li class="post-list-item"><a class="post-list-link" href="/Pycharm/">Pycharm</a></li><li class="post-list-item"><a class="post-list-link" href="/maoyan_encrypt/">Python爬虫--猫眼加密字符</a></li><li class="post-list-item"><a class="post-list-link" href="/laravel_admin/">PHP框架--Laravel</a></li><li class="post-list-item"><a class="post-list-link" href="/django/">Django</a></li><li class="post-list-item"><a class="post-list-link" href="/quick_sort/">Python算法--快速排序</a></li><li class="post-list-item"><a class="post-list-link" href="/insert_sort/">Python算法--插入排序</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">2048.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//lib.baomitu.com/fancybox/3.5.2/jquery.fancybox.min.css"><script type="text/javascript" src="/js/search.js?v=0.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" color="0,0,0" opacity="0.5" zindex="-2" count="50" src="//lib.baomitu.com/canvas-nest.js/2.0.3/canvas-nest.umd.js"></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>